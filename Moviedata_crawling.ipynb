{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MinGyeongdo/Sesion2_projcet/blob/main/Moviedata_crawling.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install requests\n",
        "!pip install bs4\n",
        "!pip install fake_useragent"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hlvko_4PwmOx",
        "outputId": "bd19e45c-46a0-4aed-fd65-5058c6d570e7"
      },
      "id": "Hlvko_4PwmOx",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (2.23.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests) (2022.6.15)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests) (3.0.4)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: bs4 in /usr/local/lib/python3.7/dist-packages (0.0.1)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.7/dist-packages (from bs4) (4.6.3)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting fake_useragent\n",
            "  Downloading fake-useragent-0.1.11.tar.gz (13 kB)\n",
            "Building wheels for collected packages: fake-useragent\n",
            "  Building wheel for fake-useragent (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fake-useragent: filename=fake_useragent-0.1.11-py3-none-any.whl size=13502 sha256=136f0af2231219ff5d7b70a61776336005bc8fcdd31a0b9ba62aee4291a3e9e2\n",
            "  Stored in directory: /root/.cache/pip/wheels/ed/f7/62/50ab6c9a0b5567267ab76a9daa9d06315704209b2c5d032031\n",
            "Successfully built fake-useragent\n",
            "Installing collected packages: fake-useragent\n",
            "Successfully installed fake-useragent-0.1.11\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 해당 코드는 다음 블로그 : https://developer-ankiwoong.tistory.com/843?category=847288 를 참고하여 작성하였습니다.\n",
        "\n",
        "- 참고자료\n",
        "https://warm-uk.tistory.com/43"
      ],
      "metadata": {
        "id": "Y0J_UW_Mi_ie"
      },
      "id": "Y0J_UW_Mi_ie"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f300ce1f",
      "metadata": {
        "id": "f300ce1f"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "from requests import get\n",
        "from bs4 import BeautifulSoup\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from fake_useragent import UserAgent\n",
        "\n",
        "from time import sleep\n",
        "from random import randint"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1842122c",
      "metadata": {
        "id": "1842122c",
        "outputId": "a462c892-c9fe-428b-e529-1f7e56ed37ed",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Error occurred during loading data. Trying to use cache server https://fake-useragent.herokuapp.com/browsers/0.1.11\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/fake_useragent/utils.py\", line 154, in load\n",
            "    for item in get_browsers(verify_ssl=verify_ssl):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/fake_useragent/utils.py\", line 99, in get_browsers\n",
            "    html = html.split('<table class=\"w3-table-all notranslate\">')[1]\n",
            "IndexError: list index out of range\n"
          ]
        }
      ],
      "source": [
        "# Useragent 생성 및 header 정보 생성\n",
        "ua = UserAgent(verify_ssl=False)\n",
        "headers = {'User-Agent' : ua.random}"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 구글의 개발자 도구를 사용하여 해당 블럭에 매칭 되는 HTML 코드를 탐색하고, Feature들을 활용한 평점 예측 모델을 만들기 위하여 최신 데이터를 수집하는 과정입니다."
      ],
      "metadata": {
        "id": "H868PD4ejMfF"
      },
      "id": "H868PD4ejMfF"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8be373c1",
      "metadata": {
        "id": "8be373c1"
      },
      "outputs": [],
      "source": [
        "titles = []\n",
        "years = []\n",
        "imdp_ratings = []\n",
        "meta_scores = []\n",
        "votes = []\n",
        "genres=[]\n",
        "directors=[]\n",
        "actors=[]\n",
        "votes=[]\n",
        "grosses=[]\n",
        "movie_rates=[]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3f4f86ae",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3f4f86ae",
        "outputId": "35c7a042-1c42-46cd-bd84-47f9e050f809"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Titles:  50000\n",
            "Years:  50000\n",
            "IMDP Ratings:  50000\n",
            "Genres:  50000\n",
            "META스코어:  50000\n",
            "Directors :  50000\n",
            "Actors :  50000\n",
            "Votes :  50000\n",
            "Grosses :  50000\n",
            "Movie rates :  50000\n"
          ]
        }
      ],
      "source": [
        "\"\"\"\n",
        "&start=251&ref_=adv_nxt -> 다음페이지 규칙\n",
        "\"\"\"\n",
        "import re\n",
        "\n",
        "pages = np.arange(1,50001, 250)\n",
        "for page in pages:\n",
        "    page = requests.get(\n",
        "        \"https://www.imdb.com/search/title/?title_type=feature&release_date=1980-01-01,2022-06-30&user_rating=1.0,10.0&colors=color&languages=en&count=250&start=\"\n",
        "        + str(page)\n",
        "        + \"&ref_=adv_nxt\", headers=headers)\n",
        "    soup = BeautifulSoup(page.text, \"html.parser\") # html 파싱\n",
        "    movie_div = soup.find_all('div', class_='lister-item mode-advanced')\n",
        "    sleep(randint(2,10))\n",
        "\n",
        "    for container in movie_div:\n",
        "    # 제목  \n",
        "        name = container.h3.a\n",
        "        if name == None:\n",
        "          titles.append(np.nan)\n",
        "        else:\n",
        "          titles.append(name.text)\n",
        "   \n",
        "    # 개봉년도\n",
        "        year = container.h3.find('span', class_='lister-item-year')\n",
        "        if year == None:\n",
        "          years.append(np.nan)\n",
        "        else:\n",
        "          years.append(year.text)\n",
        "  \n",
        "    # 장르\n",
        "        genre = container.find('span', class_='genre')\n",
        "        if genre == None:\n",
        "          genres.append(np.nan)\n",
        "        else:\n",
        "          genres.append(genre.text)\n",
        "    \n",
        "    # 메타스코어\n",
        "        m_score = container.find('span','metascore')\n",
        "        if m_score == None:\n",
        "          meta_scores.append(np.nan)\n",
        "        else:\n",
        "          m_score = m_score.text\n",
        "          meta_scores.append(m_score)\n",
        "    \n",
        "    # IMDP rates\n",
        "        imdp = container.find('strong')\n",
        "        if imdp == None:\n",
        "          imdp_ratings.append(np.nan)\n",
        "        else:\n",
        "          imdp = imdp.text\n",
        "          imdp_ratings.append(imdp)\n",
        "\n",
        "    # Director\n",
        "          director = container.find('h3', class_ ='lister-item-header').findNext('p').findNext('p').findNext('p')\n",
        "        if director == None:\n",
        "          directors.append(np.nan)\n",
        "        else:\n",
        "          director = director.text.replace('\\n','').replace(' ','').replace(':','').replace('|', '')\n",
        "          p = re.compile('{}(.*){}'.format(re.escape('Director'), re.escape('Stars')))\n",
        "          director = p.findall(director)\n",
        "          directors.append(director)\n",
        "\n",
        "      # Actor\n",
        "          actor = container.find('h3', class_ ='lister-item-header').findNext('p').findNext('p').findNext('p')\n",
        "        if actor == None:\n",
        "          actors.append(np.nan)\n",
        "        else:\n",
        "          actor = actor.text.replace('\\n','').replace(' ','').replace(':','').replace('|', '')\n",
        "          p = re.compile('{}(.*){}'.format(re.escape('Stars'), re.escape(',')))\n",
        "          actor = p.findall(actor)\n",
        "          actors.append(actor)\n",
        "\n",
        "     # Vote\n",
        "          vote = container.find('span', attrs={'name' : 'nv'})\n",
        "        if vote == None:\n",
        "          votes.append(np.nan)\n",
        "        else:\n",
        "          vote = vote['data-value']\n",
        "          votes.append(vote)\n",
        "\n",
        "     # Movie rates\n",
        "          rate = container.find('span', class_='certificate')\n",
        "        if rate == None:\n",
        "          movie_rates.append(np.nan)\n",
        "        else:\n",
        "          movie_rates.append(rate.text)\n",
        "     # Gross     \n",
        "    for container in movie_div:\n",
        "         gross = container.find('p', class_='sort-num_votes-visible')\n",
        "\n",
        "         if gross == None:\n",
        "           grosses.append(np.nan)\n",
        "         else:\n",
        "           gross = gross.text.replace('\\n','')\n",
        "           p = re.compile('{}(.*){}'.format(re.escape('Gross:'), re.escape('')))\n",
        "           gross = p.findall(gross)\n",
        "           if gross == '':\n",
        "             grosses.append(np.nan)\n",
        "           else:\n",
        "             grosses.append(gross)\n",
        "\n",
        "# Data Frame 생성\n",
        "movie = pd.DataFrame({\n",
        "    'titles' : titles,\n",
        "    'years' : years,\n",
        "    'imdp_ratings' : imdp_ratings,\n",
        "    'meta_scores' : meta_scores,\n",
        "    'votes' : votes,\n",
        "    'genres' : genres,\n",
        "    'directors' : directors,\n",
        "    'actors' : actors,\n",
        "    'movie_rates' : movie_rates,\n",
        "    'grosses' : grosses,\n",
        "})\n",
        "# 알맞은 데이터수량이 들어 갔는지 확인\n",
        "print(\"Titles: \", len(titles))\n",
        "print(\"Years: \", len(years))\n",
        "print(\"IMDP Ratings: \", len(imdp_ratings))\n",
        "print(\"Genres: \", len(genres))\n",
        "print(\"META스코어: \", len(meta_scores))\n",
        "print(\"Directors : \", len(directors))\n",
        "print(\"Actors : \", len(actors))\n",
        "print(\"Votes : \", len(votes))\n",
        "print(\"Grosses : \", len(grosses))\n",
        "print(\"Movie rates : \", len(movie_rates))\n",
        "\n",
        "movie.to_csv('movies.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 해당 코드를 간단하게 설명하면, 1~50000까지의 인기도순으로 정렬한 영화정보 데이터를 추출할 Feature의 Data가 담겨있는 HTML코드를 파싱하여 필요한 데이터를 정규식과 soup라이브러리의 기능을 통해 추출하였습니다. 총 소요시간은 30분 소요되었습니다."
      ],
      "metadata": {
        "id": "iz0CGcRZUBRa"
      },
      "id": "iz0CGcRZUBRa"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.5"
    },
    "colab": {
      "name": "Untitled-checkpoint.ipynb의 사본",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}